#!/usr/bin/env perl

##########################################################################################################################################################################################
#                                                                                                                                                                                        #
#                                                                                                                                                                                        #
# e-HealthRecordsRetriever, version 1.1                                                                                                                                                  #
# -------------------------------------                                                                                                                                                  #
#                                                                                                                                                                                        #        
# Last Update: 19/12/23                                                                                                                                                                  #
#                                                                                                                                                                                        #
# Author:   Abbas Alameer <abbas.alameer@ku.edu.kw>,                                                                                                                                     #
#           Bioinformatics Group, Kuwait University                                                                                                                                      #
#                                                                                                                                                                                        #
# Please email queries, suggestions, and possible bug information to the above author.                                                                                                   #
#                                                                                                                                                                                        #
##########################################################################################################################################################################################

use warnings;
use strict;
use Term::ANSIColor;
use Getopt::Long qw(GetOptions);
use Cwd qw(cwd);
use Spreadsheet::Read;
use File::HomeDir;

my $date_range;
my $url_start_date;
my $url_end_date;
my $start_year;
my $end_year;
my $i						= 1;
my $j						= 1;
my $plos_webpage			= "plos_results_page-";
my $argv_line;
my $user_eHR_query;
my $input_command_line;
my $help;
my $keep;
my $absolute_path;
my @arr_doi_web_links		= ();
my @arr_doi_ID_all			= ();
my @arr_spreadsheet_file	= ();
my @e_healthRecords			= ();
my %title_and_files			= ();
my $file					= "";
my $file_cleanup_switch   	= 1; #set switch to true (i.e. defaults to file cleanup, unless user disables switch at CLI)
my $general_dir;
my $plos_webpages_subdir;
my $doi_articles_subdir;
my $supplementary_files_subdir;
my $results_files_subdir;
my $prog_path;
my $home_dir              	= File::HomeDir -> my_home;
my $current_date_time		= date_time();

#run main() subroutine
main();


###################################################
#                                                 #
#             SUBROUTINES BELOW                   #
#             -----------------                   #
#                                                 #
###################################################

############################ SUBROUTINE 1 #######################################################
sub main {
	
	#display start-up header
	start_up();
	
	input_parameters_check();
	
	#create main run directories - ignore if already present
	$general_dir	  			= "~/e-HealthRecordsRetriever_files";
	$plos_webpages_subdir		= "~/e-HealthRecordsRetriever_files/plos_webpages/";
	$doi_articles_subdir		= "~/e-HealthRecordsRetriever_files/doi_articles/";
	$supplementary_files_subdir	= "~/e-HealthRecordsRetriever_files/supplementary_files/";
	system("mkdir -p $general_dir $plos_webpages_subdir $doi_articles_subdir $supplementary_files_subdir");
	$prog_path 					= $home_dir . "/e-HealthRecordsRetriever_files";
	
	#if user specifies that all results files should be kept, change $file_cleanup_switch to false.
	$file_cleanup_switch = 0 if defined $keep;
	
	download_plos_webpages();
	
	foreach $file (@arr_doi_web_links) {

		doi_download($file);
	}
	
	supplementary_data_finder();
	
	print color ("green"), "Processing supporting information file(s):\n", color("reset");
	
	foreach (@arr_spreadsheet_file) {
		
		spreadsheet_checker($_);
	}
	
	#my $final_directory = "$results_files_subdir" . "_$current_date_time";
	
	#system("mv $results_files_subdir $final_directory");
	
	print color ("green"), "\nRun complete.\n", color("reset");
	print color ("green"), "$input_command_line\n\n", color("reset");
	print color ("green"), "\n=========================================================================================\n", color("reset");
	print color ("green"), "Check result file: $results_files_subdir" . "$current_date_time" . "_results.txt\n", color("reset");
	print color ("green"), "e-Health Records retrieved:\n";
	
	my $results_file = "$current_date_time" . "_results.txt";
	
	#open (RES, '>', "$results_files_subdir\_$current_date_time" . "results.txt") or die "Cannot open file: \"$results_files_subdir/results/results.txt\": $!\n";
	open (RES, '>', "results.txt") or die "Cannot open file: \"$results_files_subdir/results/results.txt\": $!\n";
	
	print RES "e-Health Records retrieved:\n";
	
	foreach my $file (@e_healthRecords) {

		print color ("white"), "[$j] $file\n";
		
		print RES "[$j] Article title: \"$title_and_files{$file}\"\nSupplementary file: $file\n\n";
		
		$j++;
	}
	
	close (RES);
	
	system("mv results.txt $results_file");
	
	my $result = "$results_files_subdir" . "_" ." $current_date_time";
	
	system("mv $results_file $results_files_subdir");

	#check $file_cleanup_switch status: if "1" ==> delete large run files directory. 
	if ($file_cleanup_switch) {
		
		#remove the temp run files
		system("cd $prog_path/ && { rm -r $plos_webpages_subdir $doi_articles_subdir ; }");	
	}
}
############################ SUBROUTINE 2 #######################################################
#This subroutine prints the program details at start-up.
sub start_up {
	
	print color ("yellow"),"  
#######################################################################
#                                                                     #
#                    e-HealthRecordsRetriever v1.0                    #
#                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                    #
#                                                                     #
#                Author:  Abbas Alameer, Kuwait University            #
#                         abbas.alameer\@ku.edu.kw                     #
#                                                                     #
#                                                                     #
#                   Developed in April 2022/December 2023             #
#                     and released under GPLv2 license                #
#                                                                     #
#######################################################################\n\n\n" , color("reset");
}
############################ SUBROUTINE 3 #######################################################
#This subroutine checks all command line input switches and arguments (including optional ones).
#It warns the user if mandatory command-line input switches and arguments are missing.
sub input_parameters_check {


	my $help_message1  = "Usage: e-HealthRecordsRetriever -h [-s DISEASE_ELECTRONIC_HEALTH_RECORDS] [-d PUBLICATION_DATE_RANGE]";
	my $help_message2  = "Mandatory arguments:
  -s                    the disease-associated electronic health record as query search term
  -d                    publication date range (yyyy-MM-dd) of the electronic health record(s): ex. 2019-05-20--2019-05-25
Optional arguments:
  -f                    user-specified absolute path to save results files
  -k                    option to keep temporary files
  -h                    show help message and exit\n";
 
 
 	#get command line parameters from @ARGV and append them all in string. Used for later output at the end of a run.	
	foreach my $element (@ARGV) {
	
		if ($element !~ m/-s|-d|-k|-help/) {
		
			$argv_line .= "\"$element\" ";
			
		} else {
		
			$argv_line .= "$element ";
		}
	}

	if ($argv_line) {
		
		$input_command_line = "User input command: e-HealthRecordsRetriever $argv_line";
	}
     
    GetOptions(
        's=s'  => \$user_eHR_query,
        'd=s'  => \$date_range,
        'k'    => \$keep,
        'f:s'  => \$absolute_path,
        'h'    => \$help,
        'help' => \$help
    );
    
    if ($help) {
		
		print color ("green"), "$help_message1\n\n$help_message2", color("reset");
		exit;
	}
	
    elsif (!$user_eHR_query or !$date_range) {
			
        print color ("red"), "Error: arguments are missing...\n", color("reset");
        print color ("green"),"$help_message1\n", color("reset");
        exit;
    }
    
    #check for optional user-specified results directory and create it
	#or default to standard result directory
	if (defined $absolute_path) {
		
		$results_files_subdir = "/e-HealthRecordsRetriever_files/results/";
		
		#check for string argument (i.e. user-specified absolute path)
		if ($absolute_path =~ m/^\/\S+\/$/) {
			 
			chomp($absolute_path);
				
			#Check for forward slashes enclosing the arguments
			$results_files_subdir = "$absolute_path". "results/";
		} else {
				
			print color ("red"), "Input argument error: The directory name was not specified or should include forward slashes...\nFor example: -f \"/temp_directory/\". The script will terminate here.\n", color("reset");
			exit;
		} 
		
	} else {
			
		print color ("green"), "No user-provided temporary file path through the -f argument is present...\nSaving files to: \"~/e-HealthRecordsRetriever_files/results/\" folder...\n", color("reset");
			 
		$results_files_subdir = "/e-HealthRecordsRetriever_files/results/";
	}
	
	#after checking if the CLI's "-f" option is present or not, create results directory's path.
	$results_files_subdir = $home_dir . $results_files_subdir;
	system("mkdir -p $results_files_subdir");
}
############################ SUBROUTINE 4 #######################################################
sub download_plos_webpages {
	
	#example eHR query: "neuroblastoma+electronic health records"
	my @url_eHR_query					= split /\s+/, $user_eHR_query;
	my $url_search_term 				= shift(@url_eHR_query);
	my $file_name						= "$url_search_term";
	#example date range: "2019-5-20--2019-5-25"
	($url_start_date, $url_end_date) 	= split /--/, $date_range;
	($start_year) 						= split(/-/, $url_start_date);
	($end_year)							= split(/-/, $url_end_date);		
	#$url_search_term .= "+ "; This starting format is no longer used by PLOS One website

	foreach my $elem (@url_eHR_query) {
		
		$url_search_term .= " $elem";
	}

	#Download atom files in a recursive loop and increment page value by 1
	print color ("green"), "Starting run...\n", color("reset");
	print color ("green"), "Downloading PLOS One search results' webpages:\n", color("reset");

	while (1) {
		
		#page incremented url
		#The commented string is no longer functioning on the Plos One website. A modification was made because of the $url_search_term and a new formatted end section needed to be added. 
		#my $url_string 	= "https://journals.plos.org/plosone/search/feed/atom?filterJournals=PLoSONE&filterStartDate=$url_start_date&filterEndDate=$url_end_date&resultsPerPage=60&q=$url_search_term&sortOrder=DATE_OLDEST_FIRST&page=$i";
		my $url_string		= "https://journals.plos.org/plosone/search/feed/atom?filterJournals=PLoSONE&filterStartDate=$url_start_date&filterEndDate=$url_end_date&resultsPerPage=60&q=$url_search_term&sortOrder=DATE_OLDEST_FIRST&page=$i&utm_content=b&utm_campaign=ENG-467";
		system("cd $prog_path/plos_webpages/ && { lynx -dump \"$url_string\" > $file_name\_$plos_webpage$i ; }");
		
		my $full_filename 	= "$file_name\_$plos_webpage$i";	
		my $dir_filename 		= "$prog_path/plos_webpages/$full_filename";
		my $size = -s $dir_filename;
		#print color ("white"), "$full_filename\tSize: $size\n", color("reset");
		
		$i++; #increment page number
		
		#Check the file size before opening a file and moving to the next iteration. 
		#This is done in the event that the page limit has been exceeded by 1, stopping further downloads,
		#and this happens when the last file, considered "empty", is <= 1188KB.
		if ($size <= 1188) {
			
			system("rm $dir_filename"); #get rid of the last file, which is empty of an article list; this is our stopping point.
			last;
		} else {
			
			print color ("white"), "$full_filename\tSize: $size KB\n", color("reset");
			
			#save plos webpages in an array
			push(@arr_doi_web_links, $full_filename);
		}
	}
	
	$i--;
	#print color ("green"), "done\n", color("reset");
	#print "\$i's value is: $i\n";
	print color ("green"), "Downloading all articles' main webpages listed in:\n", color("reset");
}
############################ SUBROUTINE 5 #######################################################
sub doi_download {
	
	my $url_input_file				= $_[0];
	my @arr_doi_ID 					= ();
	my @arr_doi_url 				= ();
	my $flag 						= 0;
	my $journal_article_identifier	= "";
	my $doi_url 					= "";
	my $publication_year;
	
	#open input file
	open (FH, "$prog_path/plos_webpages/$url_input_file") or die "Cannot open file: \"$url_input_file\": $!\n";
	
	while (<FH>) {
		
		#switch flag on when our string marker is found
		if ($_ =~ /\s+\<entry\>/) { 
			
			$flag = 1; 
		} 
		
		elsif ($_ =~ /\s+\<title\>/) { 
			
			$flag += 1; 
		}
		
		elsif ($flag == 2) {
			
			#get DOI URL                       href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0175041" title="Inositol 1, 4, 5-trisphosphate-dependent nuclear calcium signals regulate angiogenesis and cell motility in triple negative breast cancer" />
			if ($_ =~ /\s+\<link\s*rel=\".+"\s*href=\"(.+\.\d+)\"\s*title=.+/) {	
				
				$doi_url = $1;
			}
			
			#get 			<published>2017-04-04T14:00:00Z</published>
			elsif ($_ =~ /\s+\<published\>(\d+)-\d+-\d+T.+/) {
				
				$publication_year	= $1;
				#my $year_limit		= $current_year - $publication_year;
				
				#if ($year_limit <= 5) {
				if ($publication_year <= $end_year and $publication_year >= $start_year) {
					
					#extract an article's DOI ID number
					if ($doi_url =~ /^https:\/\/.+\/(journal\.pone\.\d+)/) {
						
						$journal_article_identifier = $1;
						push(@arr_doi_ID, $1);
						push(@arr_doi_ID_all, $1);
					}
					
					#append the DOI url of the article in array
					push(@arr_doi_url, $doi_url);
					$flag = 0;
					
				} else {
					
					#The current article's publication date exceeds the date range specified in the -d CLI argument. 
					#Move to the next article.
					$flag = 0;
					next;
				}
			} 
		} 
	}
	
	print color ("white"), "<$url_input_file>...", color("reset");
	print "\n";
	
	my $h = 0;
	#download the DOI webpage of an article, using cURL.
	foreach (@arr_doi_url) {
		
		print "$_\n";
		
		#The actual identifier of a file is not specified (like before) and is now called "article" by default, 
		#when downloaded through cURL. This is a remote file naming issue, stemming from the actual server 
		#from which our file is downloaded. And this creates errors with opening such a file in subroutine 6. 
		#Manually specifying the filename fixes this problem.
		#system("cd $prog_path/doi_articles/ && { curl -O -C - $_ ; }");
		system("curl --retry 5 --retry-max-time 20 -s -C - $_ > $arr_doi_ID[$h]");
		
		system("mv journal.pone.* $prog_path/doi_articles");
		
		$h++;
	}
	
	print color ("white"), "done\n", color("reset");
}
############################ SUBROUTINE 6 #######################################################
sub supplementary_data_finder {
	
	my $flag				= 0;
	my $flag2				= 0;
	my $j_pone_ID			= "";
	my $supplementary_file	= "";
	my $file_format			= "";
	my $title				= "";
	
	print color ("green"), "Fetching supplementary file(s):\n", color("reset");
	
	#open each DOI webpage and check for "Data Availability line". 
	foreach $j_pone_ID (@arr_doi_ID_all) {
		
		#open input file
		open (FH, "$prog_path/doi_articles/$j_pone_ID") or die "Cannot open file: \"$j_pone_ID\": $!\n";
		
		while (<FH>) {	

			#    <title>Epidemiological and clinical features of Kawasaki disease in Spain over 5 years and risk factors for aneurysm development. (2011-2016): KAWA-RACE study group | PLOS ONE</title>
			if ($_ =~ /^\s+<title>(.+)<\/title>/) {	
				
				$title = $1;
			}
			
			#Check for the presence of keywords using a robust regex - flag any found via STDOUT
			if ($_ =~ /.*(Electronic\sHealth\sRecord|Electronic\sMedical\sRecord|Patient\sMedical\sRecord|\sEHR\s|\sEMR\s).*/ig) {
				
				$flag = 1;
			}
			
			#if ($_ =~ /.+Data\s?Availability\:.+(Supporting\s?Information\s?files).+/) {
			if ($_ =~ /.+Data\s?Availability\:.+(Supporting\s?Information).+/) {
				
				$flag2 = 1;
			}
		
			#download any supplementary files in CSV, XLS, or XLSX format files, if found.
			if ($flag && $flag2) {
			
							#<a href="https://doi.org/10.1371/journal.pone.0199920.s002">https://doi.org/10.1371/journal.pone.0199920.s002</a>
				if ($_ =~ /.+<a\shref\=\"(https\:\/\/doi\.org.+)\"\>https\:.+(XLS|XLSX|CSV).+/) {
					
					$supplementary_file 	= $1;
					my ($head, $filename)	= split(/journal./, $supplementary_file);
					$file_format			= lc($2);
					
					print color ("white"), "$filename.$file_format...", color("reset");
					system("cd $prog_path/supplementary_files/ && { lynx --dump $supplementary_file > $filename.$file_format ; }");
					
					push(@arr_spreadsheet_file, "$filename.$file_format");
					$title_and_files{"$filename\.$file_format"} = "$title";
					print color ("white"), "done\n", color("reset");
				}
			}
			
			#Switch off flag at EOF.
			#elsif ($_ =~ /^<\/html>/) {
				
				#$flag 	= 0;
				#$flag2 = 0;
				#$title	= "";
			#}
		}
		
		#Switch off flag at EOF.
		$flag 	= 0;
		$flag2 	= 0;
		$title	= "";
		close (FH);
	}
	
	#reinitialize or "empty" @arr_doi_ID array 
	@arr_doi_ID_all =  ();
}
############################ SUBROUTINE 7 #######################################################
sub spreadsheet_checker {
	
	my $spreadsheet_file  		 = $_[0];
	my ($spreadsheet_file_csv)	 = split(/\.(xls|csv|xlsx)/, $spreadsheet_file); 
	$spreadsheet_file_csv		.= ".csv";
	
	#convert the file to csv format, as the xlscat processing steps below work the fastest on ".csv" formatted files
	print color ("green"), "Converting file: \"$spreadsheet_file\" into CSV format...\n", color("reset");
	
	system("cd $prog_path/supplementary_files/ && { libreoffice --convert-to csv $spreadsheet_file ; }");
	
	print color ("green"), "Checking file: $spreadsheet_file_csv...\n", color("reset");

	my $column_total;
	my $row_total;
	my $file_extraction =  qx(xlscat $prog_path/supplementary_files/$spreadsheet_file_csv -i 3>&1 1>&2 2>&3);
	
	#file1.csv - 01: [ file1.csv ]  25 Cols,   492 Rows (Active)
			#file1.xls - 01: [ 1 ]  25 Cols,   492 Rows
	if ($file_extraction =~ /.+\]\s+(\d+)\s+Cols.?\s+(\d+)\s+Rows.*/) {
		
		$column_total	= $1;
		chomp($column_total);
		$row_total		= $2;
		chomp($row_total);
		
		print "\"$spreadsheet_file\" has $column_total columns && $row_total rows.\n";
	}
	
	if ( ($column_total > 10 && $row_total > 10) ) {
		
		#print "The spreadsheet $spreadsheet_file has a small column/row count\n";
		
		push(@e_healthRecords, $spreadsheet_file);
		system("cd $prog_path/supplementary_files/ && { cp $spreadsheet_file $results_files_subdir ; }");
		
	} 
}
############################ SUBROUTINE 8 #######################################################
#get the current date and time.
sub date_time {
	
    my ($sec, $min, $hour, $mday, $mon, $yr, $wday, $yday, $isdst) = localtime();
    my $ctime = localtime();
    my $time_hour;
    my $time_minutes; 
                                       #hour  #minutes
    if ($ctime =~ m/^\w+\s+\w+\s+\d+\s+(\d+)\:(\d+)\:\d+\s+\d+/) {
		
		$time_hour = $1;
		$time_minutes = $2;
	}
	
    my $month    = $mon + 1;
    my $year     = $yr + 1900;
    $current_date_time = "$year-0$month-$mday\_h$time_hour$time_minutes";
}
